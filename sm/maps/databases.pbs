#!/bin/sh -login
#PBS -l mem=60000mb
#PBS -l nodes=1:ppn=16
#PBS -l walltime=1000:00:00
#PBS -m abe 
#PBS -V 
#PBS -M peter.gustafson@wmich.edu
#PBS -N databases
#PBS -e z_databases.${PBS_JOBID}.e
#PBS -o z_databases.${PBS_JOBID}.o

#!/bin/bash
# Copyright (c) 2013, Peter A. Gustafson (peter.gustafson@wmich.edu)
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#
# * Redistributions of source code must retain the above copyright
#   notice, this list of conditions and the following disclaimer.
# * Redistributions in binary form must reproduce the above copyright
#   notice, this list of conditions and the following disclaimer in
#   the documentation and/or other materials provided with the
#   distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
# OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
# AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY
# WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

if [[ -f ${PBS_NODEFILE} ]]; then
    echo ------------------------------------------------------
    NODE=`sort ${PBS_NODEFILE} | uniq -c`
    HOST=`echo ${PBS_O_HOST} |cut -f1 -d.`
    echo Job is running on node ${NODE} from host ${HOST}
    echo ------------------------------------------------------
    echo PBS: qsub was run on ${PBS_O_HOST}
    echo PBS: originating queue is ${PBS_O_QUEUE}
    echo PBS: executing queue is ${PBS_QUEUE}
    echo PBS: working directory is ${PBS_O_WORKDIR}
    echo PBS: execution mode is ${PBS_ENVIRONMENT}
    echo PBS: job identifier is ${PBS_JOBID}
    echo PBS: job name is ${PBS_JOBNAME}
    echo PBS: node file is ${PBS_NODEFILE}
    echo PBS: current home directory is ${PBS_O_HOME}
    echo PBS: PATH = ${PBS_O_PATH}
    echo ------------------------------------------------------

    NP=$(cat ${PBS_NODEFILE} | wc -l)
else
    NP=32
fi
export OMP_NUM_THREADS=${NP}
NP=32

echo CYCLE=${CYCLE}, TILES=${TILES}

###############################

[[ ${PBS_O_WORKDIR} ]] && cd ${PBS_O_WORKDIR}

function updatetiles {
    #echo $0
    TYPE=`echo $0|cut -d/ -f3`
    LEVEL=`echo $0 |cut -f5 -d/`

    NONBLACK=`convert -quiet $0.tif -threshold 2% -format %[mean] info:-`

    if [[ ! $NONBLACK == 0 ]]; then
	if [[ $TYPE = sec || $TYPE = tac || $TYPE = wac || $TYPE = oth || $TYPE = rel || $TYPE = elv ]]; then
	    EXT=jpg;
	    NAME=$0.$EXT;
	    convert -quiet $0.tif -antialias -unsharp 0x3 -quality 50 ${NAME}
	else
	    EXT=png;
	    NAME=$0.$EXT;
	    convert -quiet $0.tif -antialias -dither none -remap colors-ifr-nosharp-256.png ${NAME} && optipng -quiet ${NAME}
	fi
    else
	EXT=jpg;
	NAME=$0.$EXT;
    fi	

    POS="`python -W ignore coords.py $0.tif`" 
    ## Four corners may be pulling too many tiles.  Check these files as an example
    #tiles/1402/ifr/48/3/5/ifr_05_17.png
    #tiles/1402/ifr/48/4/3/ifr_03_08.png
    echo "$NAME, $POS, $LEVEL" >> /dev/shm/files-${TILES}.csv
}

function canadaonly {
    #echo $0
    LEVEL=`echo $0 |cut -f5 -d/`
    
    POS="`python -W ignore coords.py $0.jpg`" 
    ## Four corners may be pulling too many tiles.  Check these files as an example
    #tiles/1402/ifr/48/3/5/ifr_05_17.png
    #tiles/1402/ifr/48/4/3/ifr_03_08.png
    echo "$NAME, $POS, $LEVEL" >> /dev/shm/files-${TILES}.csv
}

export -f updatetiles
export -f canadaonly

#TILES="ifh ifr sec tac wac oth"

for dir in ${TILES}; do #elv rel 
    echo ${dir}

    rootdir=${CYCLE}
    if [[ ${dir} == oth || ${dir} == elv || ${dir} == rel || ${dir} == topo ]]; then rootdir=static; fi

    [[ -f /dev/shm/files-${TILES}.csv ]] && rm /dev/shm/files-${TILES}.csv

    ## Copy the files into tmpfs to eliminate filesystem load
    mkdir -p /dev/shm/tiles/${rootdir}/${dir}
    rsync -avP --del tiles/${rootdir}/${dir}/ /dev/shm/tiles/${rootdir}/${dir}/

    cp coords.py /dev/shm/.

    pushd /dev/shm
    find tiles/${rootdir}/${dir} -name "*.tif" -print | sed s/'.tif'// | sort | 
    xargs -P ${NP} -n 1 bash -c updatetiles 

    wait

    ## Clean up
    popd

    ## Move tiles back
    rsync -avP /dev/shm/tiles/${rootdir}/${dir}/ tiles/${rootdir}/${dir}/
    rm -fr /dev/shm/tiles
    rm /dev/shm/coords.py

    ## Capture db file
    mv /dev/shm/files-${TILES}.csv files-${TILES}.csv
    [[ -f maps.${dir}.db ]] && rm maps.${dir}.db
    sed s/files.csv/files-${TILES}.csv/ importfiles.sql > tmp_importfiles.sql
    sqlite3 -init init.sql maps.${dir}.db < tmp_importfiles.sql

    if [[ ${dir} == ifr ]]; then
    	mv maps.${dir}.db maps.el.db
    elif [[ ${dir} == ifh ]]; then
    	mv maps.${dir}.db maps.eh.db
    fi
done

## for dir in topo; do #elv rel 
##     echo ${dir}
## 
##     rootdir=${CYCLE}
##     if [[ ${dir} == oth || ${dir} == elv || ${dir} == rel || ${dir} == topo ]]; then rootdir=static; fi
##     
##     [[ -f /dev/shm/files-${TILES}.csv ]] && rm /dev/shm/files-${TILES}.csv
##     
##     find tiles/${rootdir}/${dir} -name "*.jpg" -print | sed s/'.jpg'// | sort | 
##     xargs -P ${NP} -n 1 bash -c canadaonly 
##     
##     mv /dev/shm/files-${TILES}.csv files-${TILES}.csv
##     
##     [[ -f maps.${dir}.db ]] && rm maps.${dir}.db
##     sqlite3 -init init.sql maps.${dir}.db < importfiles.sql
## done
